{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42a2f021-ff22-4bc7-9e76-2995cfb8f14f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, lead, col, broadcast, expr, collect_set, size, array_contains, min , collect_list, datediff, avg, datediff, when, count, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f747b37-b0e9-464e-a044-15ad46c3eb0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, InputDFs):\n",
    "        \"\"\"\n",
    "        Abstract method for transforming the input DataFrame.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "class FirstTransform(Transformer):\n",
    "    def transform(self, InputDFs):\n",
    "        \"\"\"\n",
    "        Example transformation: Display the DataFrame.\n",
    "        \"\"\"\n",
    "        # Question 1: Customer who bought Airpods after buying iPhone using lead and lag function\n",
    "        transactionDF = InputDFs.get('transactionInput')\n",
    "        print(\"my input dataframe is below\")\n",
    "        transactionDF.show()\n",
    "        window_spec = Window.partitionBy(col(\"customer_id\")).orderBy(\"transaction_date\") \n",
    "        transformDF = transactionDF.withColumn(\"next_prod\", lead(\"product_name\").over(window_spec)) \n",
    "\n",
    "        print(\"Airpods after buying iPhone\")\n",
    "        transformDF.orderBy(\"customer_id\",\"transaction_date\").show()\n",
    "\n",
    "        # getting the final value of customer_id\n",
    "        print(\"getting the final customer id\")\n",
    "        filteredDF = transformDF.select(col(\"customer_id\")).where((col(\"product_name\") == 'iPhone') & (col(\"next_prod\")=='AirPods'))\n",
    "\n",
    "        # joing the above output with the customer data to get all the details\n",
    "        customerDF = InputDFs.get('customerInput')\n",
    "        # Applying the join operation on both using \"id\"\n",
    "        # airpodsAfterIphoneDF = customerDF.join(filteredDF, on=\"customer_id\", how=\"inner\")\n",
    "        airpodsAfterIphoneDF = customerDF.join(broadcast(filteredDF), on=\"customer_id\", how=\"inner\")\n",
    "        # airpodsAfterIphoneDF.select(col(\"customer_id\"),col(\"customer_name\"),col(\"location\")).show()\n",
    "        transformDF = airpodsAfterIphoneDF.select(col(\"customer_id\"),col(\"customer_name\"),col(\"location\"))\n",
    "        return transformDF\n",
    "\n",
    "        # Now we will learn to apply the broadcast join to reduce the shuffling process.\n",
    "\n",
    "class SecondTransform(Transformer):\n",
    "\n",
    "    def transform(self, InputDFs):\n",
    "        \"\"\"\n",
    "            Extract customers who only bought Iphone and AirPods\n",
    "        \"\"\"\n",
    "        transaction_df = InputDFs.get(\"transactionInput\")\n",
    "        customer_df = InputDFs.get(\"customerInput\")\n",
    "        # collect all the products bought by each customer\n",
    "\n",
    "        iphoneandAirpods = transaction_df.groupBy(\"customer_id\").agg( \\\n",
    "        collect_set(col(\"product_name\")).alias('collect_product'))\n",
    "\n",
    "        # collecting only elements which contains only iPhone and AirPods\n",
    "        filterDF = iphoneandAirpods.filter(\n",
    "        (size(col('collect_product')) == 2) &\n",
    "        array_contains(col('collect_product'), 'AirPods') &\n",
    "        array_contains(col('collect_product'), 'iPhone')\n",
    "        )\n",
    "        filterDF.show()\n",
    "\n",
    "        print(\"Following are the details: Customer who bought only Iphone and AirPods\")\n",
    "\n",
    "        filterDF = filterDF.join(customer_df, on=\"customer_id\", how=\"inner\").select(\"customer_id\",\"customer_name\",\"location\",\"collect_product\")\n",
    "        filterDF.show()\n",
    "        return filterDF\n",
    "    \n",
    "class ThirdTransform(Transformer):\n",
    "\n",
    "    def transform(self, InputDFs):\n",
    "        \"\"\"\n",
    "            Extract products bought by customers after initial purchase\n",
    "        \"\"\"\n",
    "        transaction_df = InputDFs.get(\"transactionInput\")\n",
    "        # get the first transaction date for all customers and then join that table to transaction table.\n",
    "\n",
    "        min_transaction_df = transaction_df.groupBy(\"customer_id\").agg(\n",
    "        min(\"transaction_date\").alias(\"min_date\")\n",
    "        )\n",
    "        join_products_df = transaction_df.join(min_transaction_df, on=\"customer_id\", how=\"left\")\n",
    "        join_products_df.show()\n",
    "\n",
    "        print(\"List of products bought by each customer after their initial purchase\")\n",
    "        join_products_df = join_products_df.filter(expr(\"transaction_date > min_date\")).groupBy(\"customer_id\").agg(\n",
    "        collect_list(\"product_name\").alias('collect_product')\n",
    "        ).orderBy(\"customer_id\")\n",
    "        join_products_df.show()\n",
    "\n",
    "        return join_products_df\n",
    "    \n",
    "class FourthTransform(Transformer):\n",
    "\n",
    "    def transform(self, InputDFs):\n",
    "        \"\"\"\n",
    "            Average time delay between Iphone and Airpods by each customer.\n",
    "        \"\"\"\n",
    "        transaction_df = InputDFs.get(\"transactionInput\")\n",
    "        customer_df = InputDFs.get(\"customerInput\")\n",
    "        # creating two dataframes of Iphone and AirPods\n",
    "        iPhone_df = transaction_df.filter(col(\"product_name\")=='iPhone')\n",
    "        airpods_df = transaction_df.filter(col(\"product_name\")=='AirPods')\n",
    "\n",
    "        joined_df = iPhone_df.alias('a').join(airpods_df.alias('b'), (col(\"a.customer_id\")== col(\"b.customer_id\")))\n",
    "\n",
    "        joined_df = joined_df.withColumn(\n",
    "        \"time_delay\", \n",
    "        datediff(col(\"b.transaction_date\"), col(\"a.transaction_date\"))\n",
    "        ).groupBy(\n",
    "        \"a.customer_id\"\n",
    "        ).agg(\n",
    "        avg(\"time_delay\").alias(\"average_time_delay\"))\n",
    "\n",
    "        print(\"Getting the final result\")\n",
    "\n",
    "        # Join with customer_df\n",
    "        joined_df = joined_df.join(\n",
    "        customer_df.alias('c'),  # Use an alias to avoid ambiguity\n",
    "        on=col(\"a.customer_id\") == col(\"c.customer_id\"), \n",
    "        how=\"inner\"\n",
    "        ).select(\n",
    "        col(\"a.customer_id\"),    # Use the correct alias to disambiguate\n",
    "        col(\"c.customer_name\"), \n",
    "        col(\"c.location\"), \n",
    "        col(\"average_time_delay\")\n",
    "        )\n",
    "        joined_df.show()\n",
    "\n",
    "        return joined_df\n",
    "    \n",
    "class FifthTransform(Transformer):\n",
    "\n",
    "    def transform(self, InputDFs):\n",
    "        \"\"\"\n",
    "            ETL pipeline to extract top 3 products by total revenue.\n",
    "        \"\"\"\n",
    "        transaction_df = InputDFs.get(\"transactionInput\")\n",
    "        products_df = InputDFs.get(\"productInput\")\n",
    "\n",
    "        # Updating the product_name in products_df. So that we can join both the dataframes.\n",
    "        products_df = products_df \\\n",
    "        .withColumn(\"product_name\", when(col(\"product_name\")=='iPhone SE','iPhone').otherwise(col(\"product_name\"))) \\\n",
    "        .withColumn(\"product_name\", when(col(\"product_name\")=='AirPods Pro','AirPods').otherwise(col(\"product_name\"))) \\\n",
    "        .withColumn(\"product_name\", when(col(\"product_name\")=='MacBook Air','MacBook').otherwise(col(\"product_name\"))) \\\n",
    "        .withColumn(\"product_name\", when(col(\"product_name\")=='iPad Mini','iPad').otherwise(col(\"product_name\")))\n",
    "\n",
    "        print(\"Getting the top 3 products by total revenue\")\n",
    "\n",
    "        top_products = transaction_df.groupBy(\"product_name\").count().alias(\"product_sold\")\n",
    "        final_df = top_products.join(products_df, on=\"product_name\", how=\"inner\")\n",
    "        final_df = final_df.withColumn(\"total_revenue\",expr(\"price*count\")).orderBy(col(\"total_revenue\"), ascending=False).limit(3)\n",
    "\n",
    "        final_df.show()\n",
    "\n",
    "        return final_df\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transform_file",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
